{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg3yVV-zjev_"
      },
      "source": [
        "# Week2_1 Assignment\n",
        "\n",
        "# [BASIC](#Basic)\n",
        "- BERT 모델의 hidden state에서 **특정 단어의 embedding을 여러 방식으로 추출 및 생성**할 수 있다.\n",
        "\n",
        "# [CHALLENGE](#Challenge)\n",
        "- **cosine similarity 함수를 구현**할 수 있다. \n",
        "- **단어들의 유사도**를 cosine similarity로 비교할 수 있다. \n",
        "\n",
        "# [ADVANCED](#Advanced)\n",
        "- 문장 embedding을 구해 **문장 간 유사도**를 구할 수 있다.\n",
        "\n",
        "### Reference\n",
        "- [BERT word embedding & sentence embedding tutorial 영문 블로그](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#33-creating-word-and-sentence-vectors-from-hidden-states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "audBCE5fjSMC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import torch\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T03wL1uH1HHb"
      },
      "source": [
        "## Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvJncy-fjkUV"
      },
      "source": [
        "### BERT 모델과 토크나이저 로드   \n",
        "- 두 사람의 대화에서 (단어 및 문장의) embedding을 생성하고자 한다. 아래 대화를 BERT 모델에 입력해 출력값 중 \"hidden states\"값을 가져오자.\n",
        "- `Hidden States`는 3차원 텐서를 가지고 있는 list 타입이다. List에는 BERT 모델의 각 layer마다의 hidden state 3차원 텐서를 갖고 있으며 각 텐서는 (batch_size, sequence_length, hidden_size) shape을 가진다. BERT-base 모델은 12 layer를 갖고 있고 이와 별도로 Embedding Layer 1개를 더 갖고 있기 때문에 `len(hidden states)`는 13개가 된다. \n",
        "    - batch_size: 학습 시 설정한 배치 사이즈. 또는 BERT 모델에 입력된 문장의 개수\n",
        "    - sequence_length: 문장의 token의 개수. \n",
        "    - hidden size: token의 embedding size \n",
        "- Reference\n",
        "    - [BertTokenizer.tokenize() 함수의 매개변수 설명](https://huggingface.co/transformers/v3.0.2/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.__call__)\n",
        "    - [BERTModel.forward() 함수의 매개변수 및 리턴 값 설명](https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertModel.forward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "bcmmeNkujk0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc21139e-b626-4d60-feb6-14133bcba7cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "GZqEFuRHjgBj"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "NXyCD5dnjo37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6832b8b1-bd9a-4b56-9a96-830e56976a54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "tokenizer_bert = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "model_bert = BertModel.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "Q-UbcLH4juKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ce99c10-923b-4258-8356-88cd90ffc7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal Person asked: what do you do when you have free time?\n",
            "Nerd answers: I code. code frees my minds, body and soul.\n",
            "Normal Person asked: (what a nerd...) coding?\n",
            "Nerd answers: Yes. coding is the best thing to do in the free time.\n",
            "['what do you do when you have free time?', '(what a nerd...) coding?']\n",
            "['I code. code frees my minds, body and soul.', 'Yes. coding is the best thing to do in the free time.']\n",
            "(2,)\n",
            "(2,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "normal_person = [\"what do you do when you have free time?\"]\n",
        "nerd = [\"I code. code frees my minds, body and soul.\"]\n",
        "normal_person.append(\"(what a nerd...) coding?\")\n",
        "nerd.append(\"Yes. coding is the best thing to do in the free time.\")\n",
        "\n",
        "for i in range(len(normal_person)):\n",
        "    print(f\"Normal Person asked: {normal_person[i]}\")\n",
        "    print(f\"Nerd answers: {nerd[i]}\")\n",
        "\n",
        "print(normal_person)\n",
        "print(nerd)\n",
        "print(np.array(normal_person).shape)\n",
        "print(np.array(nerd).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "KQtKFM-hjvVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "309644d8-9f30-48b0-bbf1-c1a2f4753ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1184,  1202,  1128,  1202,  1165,  1128,  1138,  1714,  1159,\n",
            "           136,   102,   146,  3463,   119,  3463,  1714,  1116,  1139, 10089,\n",
            "           117,  1404,  1105,  3960,   119,   102,     0,     0],\n",
            "        [  101,   113,  1184,   170, 24928,  2956,   119,   119,   119,   114,\n",
            "         19350,   136,   102,  2160,   119, 19350,  1110,  1103,  1436,  1645,\n",
            "          1106,  1202,  1107,  1103,  1714,  1159,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1]])}\n",
            "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "torch.Size([2, 28])\n"
          ]
        }
      ],
      "source": [
        "# 매개변수 설명\n",
        "# truncation <- max_len 넘어가지 않도록 자르기\n",
        "# padding <- max(seq_len, max_len) zero padding\n",
        "# return_tensors <- return 2d tensor \n",
        "\n",
        "inputs = tokenizer_bert(\n",
        "    text = normal_person,\n",
        "    text_pair = nerd,\n",
        "    truncation = True,\n",
        "    padding = \"longest\", \n",
        "    return_tensors='pt'\n",
        "    )\n",
        "print(inputs)\n",
        "print(inputs.keys())\n",
        "print(inputs['input_ids'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "zjua8EtijyJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0045dbf2-299d-4810-eeda-388befe7a8e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coversation 0 -> '[CLS] what do you do when you have free time? [SEP] I code. code frees my minds, body and soul. [SEP] [PAD] [PAD]'\n",
            "Coversation 1 -> '[CLS] ( what a nerd... ) coding? [SEP] Yes. coding is the best thing to do in the free time. [SEP]'\n"
          ]
        }
      ],
      "source": [
        "# decoding\n",
        "for i in range(len(inputs['input_ids'])):\n",
        "    print(f\"Coversation {i} -> '{tokenizer_bert.decode(inputs['input_ids'][i])}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "ggtYUkbejzBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb6fe48-e90b-492f-aa9e-4db74ab865a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3463]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "# \"code\" 단어의 token id(각 단어에게 고유하게 주어진 id)를 출력\n",
        "tokenizer_bert.encode('code', add_special_tokens=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "XZUxJJxkj0NG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea5568c0-670d-4c3d-e1bc-96bd09f53476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "S5TrsQ_Wj09O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba9b4a22-7012-42d6-8456-ab79a68a8617"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "# 입력 데이터와 BERT 모델을 \"GPU\" 장치로 로드함\n",
        "inputs = inputs.to(device)\n",
        "model_bert.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "_FGm_9rtj1xw"
      },
      "outputs": [],
      "source": [
        "# 입력 데이터를 BERT 모델에 넣어 출력값을 가져옴\n",
        "outputs = model_bert(\n",
        "    **inputs, \n",
        "    output_hidden_states=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs['hidden_states'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdy_g2zlh_Uz",
        "outputId": "0e90eafe-68dd-4299-f61a-dc596adc3121"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[ 4.4960e-01,  9.7664e-02, -2.0737e-01,  ...,  5.7809e-02,\n",
            "           4.0619e-02, -9.5125e-02],\n",
            "         [-7.8738e-01, -1.0678e+00,  3.5689e-02,  ..., -4.7092e-01,\n",
            "          -5.4388e-01,  4.5083e-01],\n",
            "         [ 1.4508e-02, -6.8737e-01, -7.4821e-01,  ...,  1.4196e+00,\n",
            "           2.9521e-01,  5.0731e-01],\n",
            "         ...,\n",
            "         [-3.9978e-02, -5.4787e-01,  4.4716e-01,  ...,  5.0490e-01,\n",
            "          -6.8416e-01,  6.4436e-01],\n",
            "         [ 4.9496e-01, -1.1683e+00,  8.7425e-01,  ...,  4.9406e-01,\n",
            "          -4.4909e-01,  8.2968e-01],\n",
            "         [ 2.8694e-01, -1.1871e+00,  7.9515e-01,  ...,  2.5629e-01,\n",
            "          -3.8745e-01,  6.6180e-01]],\n",
            "\n",
            "        [[ 4.4960e-01,  9.7664e-02, -2.0737e-01,  ...,  5.7809e-02,\n",
            "           4.0619e-02, -9.5125e-02],\n",
            "         [-1.5650e+00,  8.4825e-01,  1.0760e-01,  ...,  2.7933e-01,\n",
            "          -4.6456e-01,  7.5631e-01],\n",
            "         [-5.7274e-01, -1.1505e+00,  1.9704e-01,  ..., -4.7821e-01,\n",
            "          -6.2702e-01,  3.6029e-01],\n",
            "         ...,\n",
            "         [ 2.6956e-01,  1.1440e-01,  8.0437e-02,  ...,  5.3174e-01,\n",
            "           8.3109e-01,  2.1111e-01],\n",
            "         [-2.2145e-01,  9.8700e-02,  1.2106e+00,  ...,  2.0788e-01,\n",
            "           4.0735e-01,  5.4336e-01],\n",
            "         [-6.9814e-05, -6.5386e-01,  5.0624e-01,  ...,  2.6290e-01,\n",
            "          -7.0469e-01,  5.9333e-01]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.2894, -0.0200, -0.1122,  ...,  0.0163,  0.0052, -0.1514],\n",
            "         [-0.9176, -1.7562, -0.3767,  ..., -1.0655, -0.9698,  0.2481],\n",
            "         [ 0.4223, -0.9337, -1.0101,  ...,  1.1541,  0.2650,  0.4191],\n",
            "         ...,\n",
            "         [-0.0890, -0.7597,  0.4321,  ...,  0.5864, -0.7323,  0.7080],\n",
            "         [-0.7024,  0.0735,  0.4204,  ..., -0.5965,  0.1634,  0.2057],\n",
            "         [-0.9686,  0.1684,  0.3614,  ..., -0.7733,  0.2664,  0.0847]],\n",
            "\n",
            "        [[ 0.3249, -0.0200, -0.0817,  ...,  0.0785,  0.0356, -0.1608],\n",
            "         [-1.5228,  0.6187, -0.0820,  ..., -0.0065, -0.3533,  0.7728],\n",
            "         [-0.3550, -2.0406,  0.1893,  ..., -1.0585, -1.0767,  0.0671],\n",
            "         ...,\n",
            "         [ 0.3078, -0.0304,  0.1222,  ..., -0.0982,  0.8414,  0.3479],\n",
            "         [ 0.3223, -0.2599,  0.7413,  ..., -0.2247,  0.2050,  0.2573],\n",
            "         [-0.1495, -0.8325,  0.4866,  ...,  0.5047, -0.8179,  0.5517]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 3.9876e-01,  7.3663e-02, -1.3360e-01,  ..., -1.2892e-01,\n",
            "           6.0459e-02, -3.0871e-01],\n",
            "         [-2.9249e-01, -2.0228e+00, -3.2224e-01,  ..., -6.8134e-01,\n",
            "          -9.6508e-01, -6.2645e-01],\n",
            "         [ 5.2723e-01, -7.3511e-01, -8.6817e-01,  ...,  1.3935e+00,\n",
            "           3.5795e-01, -2.1095e-01],\n",
            "         ...,\n",
            "         [ 2.5993e-02, -2.3920e-01,  1.3942e-01,  ...,  1.9396e-01,\n",
            "          -2.0491e-01,  1.2375e-01],\n",
            "         [-6.1478e-01, -3.7216e-02, -3.4551e-02,  ..., -8.0729e-01,\n",
            "           2.7568e-01,  3.2700e-01],\n",
            "         [-4.9350e-01, -2.1365e-02,  1.1165e-03,  ..., -9.2191e-01,\n",
            "           1.9028e-01, -6.2514e-02]],\n",
            "\n",
            "        [[ 4.7158e-01,  2.6376e-02, -3.1132e-02,  ..., -6.1595e-02,\n",
            "           4.7216e-02, -2.7015e-01],\n",
            "         [-5.5008e-01,  5.5297e-01, -2.1600e-01,  ...,  4.1425e-02,\n",
            "          -1.6323e-01,  7.9940e-01],\n",
            "         [-3.9835e-01, -2.6793e+00, -1.6871e-02,  ..., -5.9222e-01,\n",
            "          -1.3021e+00, -1.5460e-01],\n",
            "         ...,\n",
            "         [ 3.7895e-01, -3.4992e-01,  2.8168e-01,  ..., -2.2202e-01,\n",
            "           7.7665e-01,  5.2618e-01],\n",
            "         [ 3.9497e-01, -3.3202e-01,  4.0983e-01,  ..., -8.5996e-01,\n",
            "           1.4789e-01,  3.1334e-01],\n",
            "         [-1.9738e-02, -2.6987e-01,  1.3539e-01,  ...,  1.6621e-01,\n",
            "          -2.3559e-01,  7.3214e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 6.1946e-01,  2.3793e-01, -2.3241e-01,  ..., -3.8073e-01,\n",
            "           1.8418e-01, -6.1645e-02],\n",
            "         [ 1.3502e-01, -1.9499e+00, -5.4946e-01,  ..., -8.7216e-01,\n",
            "          -8.8405e-01, -1.7232e-01],\n",
            "         [ 1.0894e-01, -7.2026e-01, -6.8270e-01,  ...,  1.0343e+00,\n",
            "           5.6620e-01, -2.7947e-01],\n",
            "         ...,\n",
            "         [ 2.0654e-02, -1.1694e-01,  3.9004e-02,  ..., -2.2492e-03,\n",
            "          -5.1465e-02,  5.6766e-02],\n",
            "         [-4.5244e-01, -1.3473e-01, -2.1908e-01,  ..., -6.8792e-01,\n",
            "           3.0253e-01,  2.9644e-01],\n",
            "         [-3.3868e-01, -7.2302e-02, -1.7518e-01,  ..., -8.6434e-01,\n",
            "           1.1463e-01, -1.2481e-01]],\n",
            "\n",
            "        [[ 7.9220e-01,  2.6928e-01, -1.1832e-01,  ..., -1.7198e-01,\n",
            "           5.9864e-02,  3.1110e-02],\n",
            "         [-8.4997e-01,  1.0030e+00, -3.2706e-01,  ...,  1.6842e-01,\n",
            "          -1.3976e-01,  1.0934e+00],\n",
            "         [ 2.9044e-03, -2.7577e+00,  1.6652e-01,  ..., -5.9202e-01,\n",
            "          -1.0386e+00, -2.3370e-01],\n",
            "         ...,\n",
            "         [ 5.7910e-01,  5.1903e-01,  8.3646e-01,  ...,  1.8073e-01,\n",
            "           6.9487e-01, -1.3372e-01],\n",
            "         [ 6.6455e-01, -2.2675e-01,  2.7395e-01,  ..., -6.8373e-01,\n",
            "           2.7128e-02,  2.1853e-01],\n",
            "         [ 3.8359e-02, -1.2213e-01,  4.2120e-02,  ..., -2.8726e-03,\n",
            "          -7.4761e-02,  3.0843e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.8571,  0.1058, -0.2287,  ..., -0.4581,  0.4188,  0.0228],\n",
            "         [-0.3622, -2.3538, -0.3923,  ..., -0.5835, -1.0600,  0.2181],\n",
            "         [-0.5434, -0.3840, -0.4233,  ...,  1.4126,  0.3764, -0.0618],\n",
            "         ...,\n",
            "         [ 0.0124, -0.0527,  0.0078,  ...,  0.0139, -0.0441, -0.0148],\n",
            "         [-0.4153, -0.2803, -0.0959,  ..., -0.6447,  0.5887,  0.4839],\n",
            "         [-0.2637, -0.3535, -0.1073,  ..., -0.9393,  0.1545, -0.0358]],\n",
            "\n",
            "        [[ 0.7608,  0.2474, -0.2819,  ..., -0.2673,  0.1323,  0.0497],\n",
            "         [-0.9741,  0.3714, -0.2920,  ...,  0.6666, -0.4717,  1.3831],\n",
            "         [-0.1604, -3.2615,  0.2790,  ..., -0.0804, -1.3094,  0.0353],\n",
            "         ...,\n",
            "         [ 0.6226,  0.7890,  0.5099,  ...,  0.3067,  1.2027,  0.1522],\n",
            "         [ 0.5331, -0.2799,  0.2520,  ..., -0.2954,  0.0857,  0.4903],\n",
            "         [ 0.0202, -0.0573,  0.0104,  ...,  0.0145, -0.0414, -0.0480]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.5201, -0.2882, -0.2331,  ..., -0.4621,  0.4832,  0.1883],\n",
            "         [-0.6010, -2.4282, -0.8064,  ...,  0.0256, -1.4281,  0.2449],\n",
            "         [-0.4927, -0.6475, -0.2927,  ...,  1.5125,  0.0578,  0.1451],\n",
            "         ...,\n",
            "         [-0.0169, -0.0423,  0.0326,  ..., -0.0305, -0.0484, -0.0480],\n",
            "         [-0.4670, -0.1377,  0.2080,  ..., -0.2846,  0.5698,  0.3903],\n",
            "         [-0.1892, -0.1262,  0.2390,  ..., -0.5414,  0.2220, -0.2181]],\n",
            "\n",
            "        [[ 0.5339,  0.1865, -0.2847,  ..., -0.2491, -0.0524,  0.0629],\n",
            "         [-0.6992,  0.2729,  0.0149,  ...,  0.5713, -0.8455,  1.4153],\n",
            "         [-0.1586, -2.9822,  0.6405,  ...,  0.1351, -1.3232,  0.0930],\n",
            "         ...,\n",
            "         [ 0.9246,  0.5461,  0.9510,  ...,  0.0074,  0.3769,  1.1491],\n",
            "         [ 0.4407, -0.0649, -0.1072,  ..., -0.2021, -0.0100,  0.4209],\n",
            "         [-0.0072, -0.0411,  0.0353,  ..., -0.0247, -0.0463, -0.0651]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.6443, -0.3632, -0.4639,  ..., -0.5752,  0.0733,  0.3334],\n",
            "         [-0.2353, -1.8418, -0.4976,  ...,  0.1955, -1.5813, -0.7917],\n",
            "         [-0.3567, -0.6438, -0.6899,  ...,  1.4446, -0.1775,  0.0153],\n",
            "         ...,\n",
            "         [-0.0360, -0.0298,  0.0278,  ..., -0.0332, -0.0205, -0.0774],\n",
            "         [-0.3047, -0.3163,  0.2359,  ..., -0.1743,  0.6604,  0.5046],\n",
            "         [-0.0349, -0.3108,  0.2232,  ..., -0.3003,  0.3117,  0.1645]],\n",
            "\n",
            "        [[ 0.8100,  0.0609, -0.5583,  ...,  0.2825, -0.5123, -0.1716],\n",
            "         [-1.1385, -0.1384, -0.0737,  ...,  0.9422, -0.0613,  1.0749],\n",
            "         [-0.1815, -2.7259,  0.4410,  ...,  0.5023, -1.0302, -0.1511],\n",
            "         ...,\n",
            "         [ 0.5775,  0.7721,  0.4334,  ...,  0.0945, -0.0508,  0.9609],\n",
            "         [ 0.8951, -0.1324, -0.1090,  ..., -0.2401, -0.0977,  0.6140],\n",
            "         [-0.0275, -0.0305,  0.0233,  ..., -0.0338, -0.0107, -0.0851]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 4.5703e-01, -2.4389e-01, -1.0477e-01,  ..., -2.2092e-01,\n",
            "           2.1152e-01,  2.5010e-01],\n",
            "         [-8.0586e-02, -1.7261e+00, -6.2863e-01,  ...,  2.3734e-01,\n",
            "          -2.0274e+00,  7.5068e-03],\n",
            "         [ 2.4627e-02, -6.7165e-01, -1.0128e+00,  ...,  1.5869e+00,\n",
            "          -7.5489e-01,  5.9635e-01],\n",
            "         ...,\n",
            "         [-4.8660e-02, -5.6711e-03,  4.9230e-02,  ..., -2.3380e-03,\n",
            "          -3.6737e-02, -8.0139e-02],\n",
            "         [-2.5458e-01, -1.0659e-01,  4.0521e-01,  ..., -3.0052e-02,\n",
            "           6.3387e-01,  4.7076e-01],\n",
            "         [-1.5309e-02, -3.4587e-01,  3.3830e-01,  ..., -2.9743e-01,\n",
            "           3.7744e-01,  3.3936e-01]],\n",
            "\n",
            "        [[ 6.8582e-01,  3.2690e-01, -8.8725e-01,  ..., -9.7440e-02,\n",
            "          -4.2584e-01,  1.6896e-01],\n",
            "         [-1.0967e+00, -2.7087e-01, -1.1407e-01,  ...,  6.0416e-01,\n",
            "           1.0438e-02,  5.3674e-01],\n",
            "         [-2.9941e-02, -2.6924e+00,  2.2457e-01,  ...,  6.4601e-01,\n",
            "          -9.0987e-01, -1.3181e-01],\n",
            "         ...,\n",
            "         [ 3.9909e-01,  3.9167e-01,  2.6180e-02,  ...,  3.4501e-01,\n",
            "           2.2329e-01,  6.6636e-01],\n",
            "         [ 4.6823e-01, -1.2529e-01,  1.3405e-01,  ..., -1.6700e-01,\n",
            "           4.6692e-02,  9.8446e-01],\n",
            "         [-4.5496e-02, -7.8566e-05,  4.7867e-02,  ..., -8.8637e-03,\n",
            "          -3.8114e-02, -8.4783e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 5.2577e-01, -2.7926e-01, -5.2838e-02,  ..., -4.0576e-01,\n",
            "           3.3807e-01,  4.8329e-01],\n",
            "         [ 1.3419e-02, -2.1901e+00, -7.2691e-01,  ..., -4.9062e-02,\n",
            "          -2.1181e+00, -1.0524e-01],\n",
            "         [ 2.1597e-01, -6.8745e-01, -1.0292e+00,  ...,  1.5798e+00,\n",
            "          -8.3210e-01,  5.8036e-01],\n",
            "         ...,\n",
            "         [-2.0592e-03,  6.2326e-02,  2.9518e-02,  ...,  1.8408e-02,\n",
            "          -6.9334e-03, -1.0446e-01],\n",
            "         [-4.2229e-01, -3.6665e-01,  2.4679e-01,  ...,  1.0063e-02,\n",
            "           9.7464e-01,  6.4631e-01],\n",
            "         [-4.1654e-01, -5.4698e-01,  6.6806e-01,  ..., -1.7866e-01,\n",
            "           5.8395e-01,  4.3021e-01]],\n",
            "\n",
            "        [[-5.8910e-02,  2.0159e-01, -9.1801e-01,  ..., -1.4423e-01,\n",
            "          -3.4803e-01,  7.6122e-01],\n",
            "         [-1.2781e+00, -4.6017e-01, -7.1980e-02,  ...,  1.0262e-01,\n",
            "           1.1043e-01,  5.2853e-01],\n",
            "         [ 2.4498e-01, -1.8417e+00, -1.6110e-01,  ...,  7.0098e-01,\n",
            "          -8.9639e-01, -8.7904e-02],\n",
            "         ...,\n",
            "         [-1.3594e-02,  3.6508e-01, -3.6297e-02,  ...,  1.0193e-01,\n",
            "           1.9010e-01,  6.5099e-01],\n",
            "         [ 3.3899e-01, -1.0638e-01, -9.0040e-02,  ...,  2.6959e-02,\n",
            "           2.5272e-02,  9.4066e-01],\n",
            "         [-2.6060e-04,  6.5574e-02,  3.1816e-02,  ...,  1.4244e-02,\n",
            "           1.0841e-03, -9.8312e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 7.5240e-01,  1.1529e-03, -4.4633e-03,  ..., -3.6023e-01,\n",
            "           8.5089e-01,  4.8185e-01],\n",
            "         [ 3.4251e-01, -2.2534e+00, -3.3509e-01,  ..., -3.6798e-01,\n",
            "          -2.4532e+00,  3.0882e-02],\n",
            "         [ 2.5001e-02, -1.0608e+00, -5.3600e-01,  ...,  1.1111e+00,\n",
            "          -1.4538e+00,  4.0594e-01],\n",
            "         ...,\n",
            "         [-1.7935e-02,  1.0391e-01,  2.9058e-02,  ...,  1.5528e-02,\n",
            "          -1.0633e-02, -1.0708e-01],\n",
            "         [-4.4183e-01, -4.3140e-01,  4.3220e-01,  ...,  9.1690e-02,\n",
            "           1.2169e+00,  4.1313e-01],\n",
            "         [-3.7593e-01, -6.6595e-01,  8.7756e-01,  ..., -2.8329e-01,\n",
            "           2.8478e-01,  4.8328e-01]],\n",
            "\n",
            "        [[ 9.9288e-05,  5.2538e-01, -8.3005e-01,  ..., -4.5240e-01,\n",
            "          -1.0696e-01,  7.0892e-01],\n",
            "         [-8.9384e-01, -1.7946e-01, -3.7074e-01,  ..., -2.9247e-01,\n",
            "           6.0994e-02,  6.6391e-01],\n",
            "         [ 5.4897e-01, -1.4381e+00,  4.0717e-03,  ...,  3.5375e-01,\n",
            "          -1.4276e+00,  4.5877e-01],\n",
            "         ...,\n",
            "         [ 3.1151e-01,  5.0922e-01,  1.7190e-01,  ..., -2.3720e-01,\n",
            "           2.7709e-01,  4.8586e-01],\n",
            "         [ 1.3914e-01,  3.5188e-02, -1.2812e-01,  ..., -3.2432e-02,\n",
            "           2.0447e-02,  5.9507e-01],\n",
            "         [-1.6653e-02,  1.0552e-01,  3.3377e-02,  ...,  1.1937e-02,\n",
            "          -7.3867e-03, -9.9483e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 1.2500e+00, -2.6364e-01,  4.7811e-01,  ...,  2.0797e-01,\n",
            "           9.7154e-01,  2.1259e-02],\n",
            "         [ 1.0727e-01, -2.0969e+00, -1.2678e-01,  ..., -2.3360e-01,\n",
            "          -1.9226e+00, -4.4811e-01],\n",
            "         [-2.7103e-01, -9.5999e-01, -4.1025e-01,  ...,  1.5039e+00,\n",
            "          -1.7656e+00,  1.0070e-01],\n",
            "         ...,\n",
            "         [-5.4554e-02,  7.4014e-02,  6.2357e-02,  ..., -1.1838e-04,\n",
            "          -1.9728e-02, -8.1425e-02],\n",
            "         [-8.4563e-01, -3.3566e-01,  3.2180e-01,  ...,  4.2521e-01,\n",
            "           8.1628e-01,  1.0684e-01],\n",
            "         [-1.2785e-02, -4.5035e-01,  9.3308e-01,  ...,  1.4810e-02,\n",
            "          -8.1630e-02,  5.5806e-01]],\n",
            "\n",
            "        [[ 4.7497e-01,  6.4409e-01, -4.4543e-01,  ...,  4.0444e-02,\n",
            "           2.8973e-01,  8.9259e-01],\n",
            "         [-4.0186e-01, -5.5122e-01,  6.7508e-02,  ...,  3.5631e-01,\n",
            "           2.1754e-02,  4.4974e-01],\n",
            "         [ 6.3366e-01, -1.2659e+00,  3.9296e-01,  ...,  7.3252e-01,\n",
            "          -1.2332e+00,  6.3938e-01],\n",
            "         ...,\n",
            "         [ 2.5548e-01,  1.9339e-01,  3.7791e-01,  ..., -7.2015e-01,\n",
            "           5.5287e-01,  6.8796e-01],\n",
            "         [ 1.6263e-02,  1.1213e-01, -2.4375e-03,  ..., -3.5850e-02,\n",
            "           3.6253e-02,  5.0920e-02],\n",
            "         [-5.1513e-02,  6.6209e-02,  4.7492e-02,  ..., -1.0029e-02,\n",
            "          -1.1297e-02, -6.9994e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 1.2765e+00, -3.0870e-01,  4.7037e-01,  ...,  2.8994e-01,\n",
            "           1.0373e+00, -2.4340e-01],\n",
            "         [ 1.0186e-01, -2.0604e+00,  5.3769e-01,  ..., -2.1474e-01,\n",
            "          -1.8352e+00, -8.7125e-01],\n",
            "         [ 5.6883e-02, -7.9033e-01, -2.3382e-02,  ...,  1.7993e+00,\n",
            "          -1.6317e+00, -8.4584e-02],\n",
            "         ...,\n",
            "         [-5.6011e-02,  7.6625e-02,  3.3241e-02,  ..., -7.6911e-04,\n",
            "           1.3855e-02, -5.3812e-02],\n",
            "         [-7.4919e-01, -6.4873e-01,  3.9713e-01,  ...,  5.3050e-01,\n",
            "           5.8227e-01, -7.3540e-02],\n",
            "         [-1.6250e-01, -3.8732e-01,  9.2912e-01,  ...,  1.4961e-01,\n",
            "          -2.9808e-02,  3.9227e-01]],\n",
            "\n",
            "        [[ 8.6188e-01,  5.2202e-01, -7.7249e-01,  ...,  1.2113e-01,\n",
            "           7.2400e-01,  5.5111e-01],\n",
            "         [-1.5251e-01, -3.6758e-01,  4.4970e-01,  ...,  7.8306e-01,\n",
            "           3.5879e-03, -2.6149e-02],\n",
            "         [ 5.9564e-01, -1.0128e+00,  5.0917e-01,  ...,  7.8185e-01,\n",
            "          -9.6442e-01,  6.9309e-01],\n",
            "         ...,\n",
            "         [ 3.5621e-01,  1.1248e-01,  4.7490e-01,  ..., -4.8983e-01,\n",
            "           5.5040e-01,  6.6725e-01],\n",
            "         [-4.0989e-02,  5.7011e-02, -1.5047e-02,  ..., -5.7159e-03,\n",
            "           2.4117e-02, -6.7745e-02],\n",
            "         [-5.0153e-02,  6.5029e-02,  3.2916e-02,  ...,  7.2554e-03,\n",
            "           1.0703e-02, -5.6863e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.6679, -0.1619,  0.0464,  ..., -0.0497,  0.2803, -0.0535],\n",
            "         [ 0.6106, -0.8639,  0.6150,  ..., -0.4122, -0.4079, -0.1688],\n",
            "         [-0.0444, -0.5049, -0.4241,  ...,  1.0809, -0.7106, -0.1930],\n",
            "         ...,\n",
            "         [ 1.7349,  0.1998, -0.2361,  ...,  0.2614,  0.1674, -0.4342],\n",
            "         [-0.0303, -0.1078,  0.1370,  ...,  0.1032,  0.2212,  0.0159],\n",
            "         [ 0.2548, -0.0262,  0.2711,  ..., -0.0726,  0.2339,  0.1456]],\n",
            "\n",
            "        [[ 0.3853,  0.1419, -0.4192,  ...,  0.2999,  0.5907,  0.4947],\n",
            "         [ 0.3261, -0.1634,  0.4139,  ...,  0.1594,  0.1886,  0.1847],\n",
            "         [ 0.4725, -0.5826,  0.3312,  ...,  0.2575, -0.4767,  0.6781],\n",
            "         ...,\n",
            "         [ 0.4010,  0.0049,  0.1142,  ..., -0.2543,  0.4962,  0.3656],\n",
            "         [ 1.1020,  0.2499, -0.3697,  ...,  1.0587,  0.5731,  0.5972],\n",
            "         [ 1.1043,  0.2280, -0.3355,  ...,  1.0730,  0.5240,  0.6639]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "s9jsHuLjj3Sy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db67a920-5591-4843-f91c-5016bcde4eb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['last_hidden_state', 'pooler_output', 'hidden_states'])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "outputs.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "I0nB31XAj4M_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b568790c-d51e-463d-fc20-4d16beef729e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# layers : 13\n",
            "tensor shape in each layer : torch.Size([2, 28, 768])\n"
          ]
        }
      ],
      "source": [
        "hidden_states = outputs['hidden_states']\n",
        "print(f\"# layers : {len(hidden_states)}\")\n",
        "print(f\"tensor shape in each layer : {hidden_states[-1].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfy3I4FXj6L_"
      },
      "source": [
        "###  Q1. 1번째 sequence (문장)에서 \"code\"라는 단어의 인덱스를 모두 반환하라.\n",
        "- \"code\" 단어는 총 2개 존재 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "_tYG4o_ho1QY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33cd919c-fabc-448e-87f1-6560ab73e629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  101,  1184,  1202,  1128,  1202,  1165,  1128,  1138,  1714,  1159,\n",
            "          136,   102,   146,  3463,   119,  3463,  1714,  1116,  1139, 10089,\n",
            "          117,  1404,  1105,  3960,   119,   102,     0,     0]) code\n",
            "[13, 15]\n"
          ]
        }
      ],
      "source": [
        "def get_index(seq, word):\n",
        "  print(seq, word)\n",
        "  index =[]\n",
        "  word_embedded = tokenizer_bert.encode(word, add_special_tokens=False)[0]\n",
        "  for idx in range(len(seq)):\n",
        "    if seq[idx] == word_embedded:\n",
        "      index.append(idx)\n",
        "  return index\n",
        "\n",
        "# input\n",
        "# seq1: 1번째 sequence\n",
        "# token: 단어\n",
        "seq1 = inputs['input_ids'][0]\n",
        "token = \"code\"\n",
        "\n",
        "\n",
        "# output\n",
        "token_index = get_index(seq1, token)\n",
        "print(token_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xopkXDS2m6uA"
      },
      "source": [
        "### Q2. 1번째 sequence의 1번째 \"code\" 토큰의 embedding을 여러가지 방식으로 구하고자 한다. BERT hidden state를 다음의 방식으로 인덱싱해 embedding을 구하라\n",
        "- 1 layer\n",
        "- last layer\n",
        "- sum all 12 layers\n",
        "- sum last 4 layers\n",
        "- concat last 4 layers\n",
        "- average last 4 layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "to7IOGNwkmUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "007194ca-3e96-4ae6-b171-74e09dfd4a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([768])\n",
            "torch.Size([3072])\n",
            "torch.Size([768])\n"
          ]
        }
      ],
      "source": [
        "# print(hidden_states)\n",
        "# print(np.array(hidden_states).shape)\n",
        "# embedding_layer + 12개 층의 (2,28,768) Tensor\n",
        "\n",
        "\n",
        "# 1 layer\n",
        "first_layer=hidden_states[1]\n",
        "first_layer_emb = first_layer[0][token_index[0]]\n",
        "print(first_layer_emb.shape)\n",
        "\n",
        "# last layer\n",
        "last_layer = hidden_states[-1]\n",
        "last_layer_emb = last_layer[0][token_index[0]]\n",
        "print(last_layer_emb.shape)\n",
        "\n",
        "# sum all 12 layers\n",
        "concat_all_layer = torch.cat([hidden_states[1].unsqueeze(dim=0),\n",
        "                                  hidden_states[2].unsqueeze(dim=0),hidden_states[3].unsqueeze(dim=0),\n",
        "                                  hidden_states[4].unsqueeze(dim=0),hidden_states[5].unsqueeze(dim=0),\n",
        "                                  hidden_states[6].unsqueeze(dim=0),hidden_states[7].unsqueeze(dim=0),\n",
        "                                  hidden_states[8].unsqueeze(dim=0),hidden_states[9].unsqueeze(dim=0),\n",
        "                                  hidden_states[10].unsqueeze(dim=0),hidden_states[11].unsqueeze(dim=0),\n",
        "                                  hidden_states[12].unsqueeze(dim=0)\n",
        "                                  ],dim = 0)\n",
        "sum_all_layer = concat_all_layer.sum(dim=0, keepdim=False)\n",
        "sum_all_layer_emb = sum_all_layer[0][token_index[0]]\n",
        "print(sum_all_layer_emb.shape)\n",
        "\n",
        "# sum last 4 layers\n",
        "concat_last4_layer = torch.cat([hidden_states[-1].unsqueeze(dim=0),\n",
        "                                  hidden_states[-2].unsqueeze(dim=0),hidden_states[-3].unsqueeze(dim=0),\n",
        "                                  hidden_states[-4].unsqueeze(dim=0)\n",
        "                                  ],dim = 0)\n",
        "sum_last4_layer = concat_last4_layer.sum(dim=0, keepdim=False)\n",
        "sum_last4_layer_emb = sum_last4_layer[0][token_index[0]]\n",
        "print(sum_last4_layer_emb.shape)\n",
        "\n",
        "# concat last 4 layers\n",
        "concat_last4_layer_emb = torch.cat([hidden_states[-1][0][token_index[0]],hidden_states[-2][0][token_index[0]],\n",
        "                                    hidden_states[-3][0][token_index[0]],hidden_states[-4][0][token_index[0]]],dim = 0)\n",
        "print(concat_last4_layer_emb.shape)\n",
        "\n",
        "# mean last 4 layers\n",
        "mean_last4_layer = concat_last4_layer.mean(dim=0)\n",
        "mean_last4_layer_emb = mean_last4_layer[0][token_index[0]]\n",
        "print(mean_last4_layer_emb.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0-C0J6o1HHl"
      },
      "source": [
        "## Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3aI-M5KubYl"
      },
      "source": [
        "### Q3. `sum_last_four_layer` 방식으로 1번째 sequence의 2개의 \"code\" 토큰 사이의 코사인 유사도를 계산하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "twWm2hrrp3qG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ee4d4f-700f-4301-931b-4e78538dc4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8427, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from torch import nn\n",
        "def cosine_similarity_manual(x, y, small_number=1e-8):\n",
        "  cos = nn.CosineSimilarity(dim=0, eps=small_number)\n",
        "  result = cos(x, y)\n",
        "  return result\n",
        "\n",
        "# input\n",
        "# x: 1번째 sequence의 1번째 \"code\"의 sum_last_four_layer 방식 embedding\n",
        "# y: 1번째 sequence의 2번째 \"code\"의 sum_last_four_layer 방식 embedding\n",
        "x = sum_last4_layer[0][token_index[0]]\n",
        "y = sum_last4_layer[0][token_index[1]]\n",
        "\n",
        "# output\n",
        "score = cosine_similarity_manual(x, y)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfc_1t2Hw8kB"
      },
      "source": [
        "### Q4. 2번째 sequence에서 \"coding\"이라는 토큰의 위치를 반환하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "B_OrrpEgw9pX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "475d35b3-0a4b-4d0d-d961-75b002c992a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  101,   113,  1184,   170, 24928,  2956,   119,   119,   119,   114,\n",
            "        19350,   136,   102,  2160,   119, 19350,  1110,  1103,  1436,  1645,\n",
            "         1106,  1202,  1107,  1103,  1714,  1159,   119,   102]) coding\n",
            "[10, 15]\n"
          ]
        }
      ],
      "source": [
        "# Q1과 동일한 문제 \n",
        "\n",
        "# input\n",
        "# seq1: 2번째 sequence\n",
        "# token: 단어\n",
        "seq2 = inputs['input_ids'][1]\n",
        "token = \"coding\"\n",
        "\n",
        "# output\n",
        "# Q1에서 구현한 함수 사용\n",
        "token_index = get_index(seq2, token)\n",
        "print(token_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c11W2Ht-xIwI"
      },
      "source": [
        "### Q5. `concat_last4_layer_emb` 방식으로 2번째 sequence의 2개의 \"coding\" 토큰 사이의 코사인 유사도를 계산하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "MXr1jtMOxKie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb880a63-9bde-47f4-f7eb-07e4fd8a3347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8682, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Q3과 동일한 문제\n",
        "\n",
        "# input\n",
        "# x: 2번째 sequence의 1번째 \"coding\"의 concat_last4_layer_emb\n",
        "# y: 2번째 sequence의 2번째 \"coding\"의 concat_last4_layer_emb\n",
        "\n",
        "x = torch.cat([hidden_states[-1][1][token_index[0]],hidden_states[-2][1][token_index[0]],\n",
        "                                    hidden_states[-3][1][token_index[0]],hidden_states[-4][1][token_index[0]]],dim = 0)\n",
        "y = torch.cat([hidden_states[-1][1][token_index[1]],hidden_states[-2][1][token_index[1]],\n",
        "                                    hidden_states[-3][1][token_index[1]],hidden_states[-4][1][token_index[1]]],dim = 0)\n",
        "# output\n",
        "# Q3에서 구현한 함수 사용\n",
        "score = cosine_similarity_manual(x, y)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doBSxlvsxlZp"
      },
      "source": [
        "### Q6. 2번째 sequence에서 랜덤하게 토큰 하나를 뽑아보자. 그 랜덤 토큰과 2번째 sequence의 2번째 \"coding\" 토큰의 코사인 유사도를 계산해보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "PajBEOs5xnOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc3ca32-8469-4586-8413-a861d18974f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5569, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# input\n",
        "# random_idx: random 모듈 사용하여 뽑은 랜덤 토큰의 인덱스\n",
        "# random_word: random_idx에 해당하는 단어\n",
        "# x: 2번째 sequence의 2번째 \"coding\" 토큰의 concat_last4_layer_emb\n",
        "# y: 랜덤 토큰의 concat_last4_layer_emb\n",
        "import random\n",
        "\n",
        "random_idx = random.randint(0,len(seq2)-1)\n",
        "random_word = tokenizer_bert.decode(inputs['input_ids'][1][random_idx])\n",
        "\n",
        "x = torch.cat([hidden_states[-1][1][token_index[1]],hidden_states[-2][1][token_index[1]],\n",
        "                                    hidden_states[-3][1][token_index[1]],hidden_states[-4][1][token_index[1]]],dim = 0)\n",
        "y = torch.cat([hidden_states[-1][1][random_idx],hidden_states[-2][1][random_idx],\n",
        "                                    hidden_states[-3][1][random_idx],hidden_states[-4][1][random_idx]],dim = 0)\n",
        "# output\n",
        "# Q3에서 구현한 함수 사용\n",
        "score = cosine_similarity_manual(x, y)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX9_cFhm1HHm"
      },
      "source": [
        "## Advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub-hubXwyw9l"
      },
      "source": [
        "### Q7. 1번째 sequence와 2번째 sequence의 문장 유사도를 구해보자. 문장의 엠베딩은 마지막 레이어의 첫번째 토큰 ('[CLS]')으로 생성한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "JpvPDM_Oyx7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493ab981-61ff-40c8-b596-307cd24b1393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 768])\n",
            "tensor(0.8130, grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# input\n",
        "# x: 1번째 sequence의 embedding\n",
        "# y: 2번째 sequence의 embedding\n",
        "print(outputs['pooler_output'].shape)\n",
        "x = last_layer[0][0] # CLS토큰 \n",
        "y = last_layer[1][0] \n",
        "\n",
        "# output\n",
        "# Q3에서 구현한 함수 사용\n",
        "score =  cosine_similarity_manual(x, y)\n",
        "print(score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "H3aI-M5KubYl"
      ],
      "name": "조한희 - Week2_1_assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}